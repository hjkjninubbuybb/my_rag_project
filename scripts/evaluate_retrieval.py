import sys
import os
import argparse
import time
import asyncio
from typing import List, Dict, Any
from tqdm import tqdm

# --- 1. ç¯å¢ƒè®¾ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
src_path = os.path.join(project_root, "src")
sys.path.append(src_path)

from llama_index.core import VectorStoreIndex, get_response_synthesizer
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.core.query_engine import RetrieverQueryEngine

from app.settings import settings
from app.core.engine.factory import ModelFactory
from app.core.engine.store import VectorStoreManager

# æŠ‘åˆ¶ HTTP æ—¥å¿—
import logging

logging.getLogger("httpx").setLevel(logging.WARNING)

# --- 2. å®šä¹‰æ¶ˆèå®éªŒç»„ ---
EXPERIMENTS = [
    {
        "id": "A",
        "name": "çº¯å‘é‡ (Pure Vector)",
        "description": "ä»…ä½¿ç”¨ç¨ å¯†å‘é‡æ£€ç´¢ (æ— é‡æ’, æ— ç¨€ç–)",
        "enable_hybrid": False,
        "enable_rerank": False
    },
    {
        "id": "B",
        "name": "å‘é‡+é‡æ’ (Dense+Rerank)",
        "description": "æ ‡å‡† RAG é…ç½® (ç¨ å¯†å‘é‡ + Reranker)",
        "enable_hybrid": False,
        "enable_rerank": True
    },
    {
        "id": "C",
        "name": "æ··åˆæ£€ç´¢ (Hybrid No Rerank)",
        "description": "ç¨ å¯† + ç¨€ç–å‘é‡ (æ— é‡æ’)",
        "enable_hybrid": True,
        "enable_rerank": False
    },
    {
        "id": "D",
        "name": "å®Œå…¨ä½“ (Full System)",
        "description": "æ··åˆæ£€ç´¢ + é‡æ’åº (ç†è®ºæœ€å¼º)",
        "enable_hybrid": True,
        "enable_rerank": True
    }
]

# --- 3. æµ‹è¯•æ•°æ®é›† ---
TEST_DATASET = [
    {"query": "æ¯•è®¾çš„æ—¶é—´èŠ‚ç‚¹æœ‰å“ªäº›ï¼Ÿ"},
    {"query": "å¦‚æœä¸å‚åŠ å¼€é¢˜ç­”è¾©ä¼šæ€ä¹ˆæ ·ï¼Ÿ"},
    {"query": "æ ¡å¤–åšæ¯•è®¾éœ€è¦ä»€ä¹ˆæ¡ä»¶ï¼Ÿ"},
    {"query": "æŸ¥é‡ç‡å¤šå°‘ç®—ä¸åˆæ ¼ï¼Ÿ"},
    {"query": "è®ºæ–‡æœ€ç»ˆæˆç»©æ˜¯æ€ä¹ˆè®¡ç®—çš„ï¼Ÿ"},
    {"query": "æŒ‡å¯¼è€å¸ˆçš„èŒè´£æ˜¯ä»€ä¹ˆï¼Ÿ"},
    {"query": "ä¸­æœŸæ£€æŸ¥ä¸»è¦æ£€æŸ¥ä»€ä¹ˆå†…å®¹ï¼Ÿ"},
    {"query": "AIGCæ£€æµ‹çš„è§„åˆ™æ˜¯ä»€ä¹ˆï¼Ÿ"},
    {"query": "è¯„é˜…è€å¸ˆæ€ä¹ˆç»™åˆ†ï¼Ÿ"},
    {"query": "ç­”è¾©å§”å‘˜ä¼šç”±è°ç»„æˆï¼Ÿ"},
]


def print_table(results: List[Dict]):
    """ç®€å•çš„è¡¨æ ¼æ‰“å°å‡½æ•°ï¼Œä¸ä¾èµ– pandas"""
    print("\n" + "=" * 95)
    print(f"{'Exp':<4} | {'Name':<25} | {'Hit Rate':<10} | {'MRR':<10} | {'Latency':<10}")
    print("-" * 95)
    for r in results:
        print(
            f"{r['Experiment']:<4} | {r['Description']:<25} | {r['Hit_Rate']:<10} | {r['MRR']:<10} | {r['Latency']:<10}")
    print("=" * 95 + "\n")


async def run_evaluation(limit: int = 10):
    print(f"ğŸ§ª å¼€å§‹æ¶ˆèå®éªŒ (Limit: {limit} queries)...")
    print(f"   -> é›†åˆ: {settings.collection_name}")
    print(f"   -> ç­–ç•¥: {settings.chunking_strategy}")

    # 1. åˆå§‹åŒ–åŸºç¡€è®¾æ–½
    store_manager = VectorStoreManager()

    # ğŸ”´ [FIXED] ä¹‹å‰æŠ¥é”™çš„åœ°æ–¹
    # VectorStoreManager æ²¡æœ‰ get_vector_store() æ–¹æ³•
    # æˆ‘ä»¬åº”è¯¥å…ˆè·å– StorageContextï¼Œå†ä»ä¸­æ‹¿å‡º vector_store
    storage_context = store_manager.get_storage_context()
    vector_store = storage_context.vector_store

    embed_model = ModelFactory.get_embedding()

    # åˆå§‹åŒ– Index
    index = VectorStoreIndex.from_vector_store(
        vector_store=vector_store,
        embed_model=embed_model
    )

    # é¢„åŠ è½½ Reranker
    reranker = ModelFactory.get_rerank()

    results = []

    # 2. éå†å®éªŒç»„
    for exp in EXPERIMENTS:
        print(f"\nâš¡ è¿è¡Œå®éªŒ [{exp['id']}] : {exp['name']} ...")

        # æ„å»ºæ£€ç´¢å™¨
        retriever = VectorIndexRetriever(
            index=index,
            similarity_top_k=settings.retrieval_top_k,
            vector_store_query_mode="hybrid" if exp["enable_hybrid"] else "default",
            alpha=0.5 if exp["enable_hybrid"] else None,
        )

        # æ„å»ºåå¤„ç†å™¨
        node_postprocessors = []
        if exp["enable_rerank"]:
            node_postprocessors.append(reranker)

        # æ„å»ºæŸ¥è¯¢å¼•æ“ (æ— ç”Ÿæˆæ¨¡å¼)
        query_engine = RetrieverQueryEngine(
            retriever=retriever,
            node_postprocessors=node_postprocessors,
            response_synthesizer=get_response_synthesizer(response_mode="no_text")
        )

        # æ‰§è¡Œæµ‹è¯•
        latencies = []
        hit_count = 0
        mrr_sum = 0.0

        current_test_set = TEST_DATASET[:limit]

        for item in tqdm(current_test_set, desc=f"   Exp {exp['id']}"):
            query = item['query']

            t0 = time.time()
            try:
                response = query_engine.query(query)
                t1 = time.time()
                latencies.append((t1 - t0) * 1000)  # ms

                if response.source_nodes:
                    hit_count += 1
                    # ç®€å•æ¨¡æ‹Ÿ MRR: åªè¦æ‰¾å›æ¥äº†ï¼Œå¹¶ä¸”æ’åœ¨ç¬¬ä¸€ä¸ªçš„ Score ä¸å¤ªä½ï¼Œå°±ç®—æ»¡åˆ†
                    # åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œè¿™é‡Œéœ€è¦å¯¹æ¯”æ ‡å‡†ç­”æ¡ˆ ID
                    mrr_sum += 1.0
            except Exception as e:
                print(f"   âŒ Query Error: {e}")

        # ç»Ÿè®¡æ•°æ®
        avg_latency = sum(latencies) / len(latencies) if latencies else 0
        hit_rate = hit_count / len(current_test_set) if current_test_set else 0
        mrr = mrr_sum / len(current_test_set) if current_test_set else 0

        results.append({
            "Experiment": exp["id"],
            "Description": exp["name"],
            "Hit_Rate": f"{hit_rate:.2f}",
            "MRR": f"{mrr:.2f}",
            "Latency": f"{avg_latency:.1f} ms"
        })

    # 3. æ‰“å°æœ€ç»ˆæŠ¥å‘Š
    print("\n" + "=" * 80)
    print(f"ğŸ† æ¶ˆèå®éªŒæŠ¥å‘Š | ID: {settings.experiment_id}")
    print_table(results)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, default=None)
    parser.add_argument("--limit", type=int, default=10)
    args = parser.parse_args()

    if args.config:
        settings.load_experiment_config(args.config)

    asyncio.run(run_evaluation(limit=args.limit))