"""
[Architecture Role: Retrieval Engine (æ£€ç´¢å¼•æ“)]
æ­¤æ¨¡å—å®ç°äº† "ä¸‰æƒåˆ†ç«‹" æ¶æ„ä¸­çš„ ã€æ£€ç´¢å±‚ã€‘ã€‚

æ ¸å¿ƒèŒè´£:
1. [Advanced Retrieval] æ„å»ºå¤æ‚çš„æ£€ç´¢æµæ°´çº¿ï¼š
   - Hybrid Search (æ··åˆæ£€ç´¢): ç»“åˆ å‘é‡ç›¸ä¼¼åº¦(è¯­ä¹‰) + å…³é”®è¯åŒ¹é…(å­—é¢)ã€‚
   - Auto-Merging (è‡ªåŠ¨åˆå¹¶): å‘½ä¸­å¤šä¸ªå­å—æ—¶ï¼Œè‡ªåŠ¨å›æº¯çˆ¶å—ä»¥æä¾›å®Œæ•´ä¸Šä¸‹æ–‡ã€‚
   - Reranking (é‡æ’åº): ä½¿ç”¨ BGE/GTE æ¨¡å‹å¯¹å¬å›ç»“æœè¿›è¡ŒäºŒæ¬¡ç²¾æ’ã€‚
2. [Bridge] å°† LlamaIndex çš„æŸ¥è¯¢å¼•æ“å°è£…ä¸º LangChain Toolï¼Œä¾› LangGraph Agent è°ƒç”¨ã€‚
"""

from llama_index.core import VectorStoreIndex
from llama_index.core.retrievers import AutoMergingRetriever
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.tools import QueryEngineTool, ToolMetadata

from app.core.engine.store import VectorStoreManager
from app.core.engine.factory import ModelFactory
from app.settings import settings


class RetrievalService:
    def __init__(self):
        self.store_manager = VectorStoreManager()
        self.llm = ModelFactory.get_llm()
        self.embed_model = ModelFactory.get_embedding()
        self.reranker = ModelFactory.get_rerank()

    def get_retriever(self, enable_hybrid: bool = True, enable_merge: bool = True):
        """
        [è¯„æµ‹ä¸“ç”¨æ¥å£] è·å–å¯é…ç½®çš„æ£€ç´¢å™¨

        Args:
            enable_hybrid (bool): æ˜¯å¦å¼€å¯æ··åˆæ£€ç´¢ã€‚
                                  True = å‘é‡+å…³é”®è¯ (Hybrid, alpha=0.5)
                                  False = çº¯å‘é‡ (Default)
            enable_merge (bool):  æ˜¯å¦å¼€å¯è‡ªåŠ¨åˆå¹¶æ£€ç´¢ (Auto-Merging)ã€‚
                                  True = è¿”å›çˆ¶æ–‡æ¡£
                                  False = è¿”å›åŸå§‹åˆ‡ç‰‡
        """
        # 1. è·å–ä¸Šä¸‹æ–‡
        storage_context = self.store_manager.get_storage_context()
        index = VectorStoreIndex.from_vector_store(
            vector_store=storage_context.vector_store,
            storage_context=storage_context,
            embed_model=self.embed_model
        )

        # 2. é…ç½®åŸºç¡€æ£€ç´¢æ¨¡å¼ (Baseline vs Hybrid)
        # å¦‚æœ enable_hybrid ä¸º Falseï¼Œåˆ™ä½¿ç”¨ "default" æ¨¡å¼ (å³çº¯å‘é‡æ£€ç´¢)
        vector_mode = "hybrid" if enable_hybrid else "default"
        alpha_value = 0.5 if enable_hybrid else None

        base_retriever = index.as_retriever(
            similarity_top_k=settings.retrieval_top_k,  # åˆç­›æ•°é‡ (ä¾‹å¦‚ 50)
            vector_store_query_mode=vector_mode,
            alpha=alpha_value
        )

        # 3. é…ç½®ç»“æ„åŒ–æ£€ç´¢ (Auto-Merging)
        if enable_merge:
            return AutoMergingRetriever(
                vector_retriever=base_retriever,
                storage_context=storage_context,
                verbose=False  # è¯„æµ‹æ—¶å…³é—­æ—¥å¿—ï¼Œä¿æŒæ¸…çˆ½
            )
        else:
            return base_retriever

    def get_query_engine(self):
        """
        æ„å»ºå¸¦æœ‰ [è‡ªåŠ¨åˆå¹¶] + [æ··åˆæ£€ç´¢] + [é‡æ’åº] åŠŸèƒ½çš„æŸ¥è¯¢å¼•æ“
        """
        # 1. é‡æ–°åŠ è½½ Index
        storage_context = self.store_manager.get_storage_context()

        index = VectorStoreIndex.from_vector_store(
            vector_store=storage_context.vector_store,
            storage_context=storage_context,
            embed_model=self.embed_model
        )

        # 2. åŸºç¡€æ£€ç´¢å™¨ (Leaf Node Level)
        base_retriever = index.as_retriever(
            similarity_top_k=settings.retrieval_top_k,
            # ğŸ‘‡ã€ä¿®å¤ã€‘æ”¹å›å­—ç¬¦ä¸²æ¨¡å¼ï¼Œå¹¶æ·»åŠ  type: ignore è®© IDE é—­å˜´
            # è¿™æ ·æ—¢ä¸ä¼šæŠ¥é”™ï¼Œä¹Ÿæ²¡æœ‰é»„è‰²æ³¢æµªçº¿
            vector_store_query_mode="hybrid",  # type: ignore
            alpha=0.5
        )

        # 3. è‡ªåŠ¨åˆå¹¶æ£€ç´¢å™¨ (Auto-Merging)
        retriever = AutoMergingRetriever(
            vector_retriever=base_retriever,
            storage_context=storage_context,
            verbose=True
        )

        # 4. æ„å»ºå¼•æ“ (Retriever + LLM)
        query_engine = RetrieverQueryEngine.from_args(
            retriever=retriever,
            llm=self.llm,
            node_postprocessors=[self.reranker]
        )

        return query_engine

    def as_langchain_tool(self):
        """
        è½¬æ¢ä¸º LangChain Toolï¼Œä¾› LangGraph ä½¿ç”¨
        """
        query_engine = self.get_query_engine()

        tool = QueryEngineTool(
            query_engine=query_engine,
            metadata=ToolMetadata(
                name="knowledge_base_search",
                description="ç”¨äºæ£€ç´¢å†…éƒ¨æ–‡æ¡£çŸ¥è¯†åº“ã€‚è¾“å…¥å®Œæ•´çš„é—®é¢˜è¿›è¡ŒæŸ¥è¯¢ã€‚",
            ),
        )

        return tool.to_langchain_tool()