from llama_index.core import VectorStoreIndex
from llama_index.core.retrievers import AutoMergingRetriever
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.tools import QueryEngineTool, ToolMetadata

from app.core.engine.store import VectorStoreManager
from app.core.engine.factory import ModelFactory
# ğŸ‘‡ã€æ–°å¢ã€‘å¯¼å…¥ settings
from app.settings import settings


class RetrievalService:
    def __init__(self):
        self.store_manager = VectorStoreManager()
        self.llm = ModelFactory.get_llm()
        self.embed_model = ModelFactory.get_embedding()
        # ğŸ‘‡ã€æ–°å¢ã€‘åˆå§‹åŒ– Reranker
        self.reranker = ModelFactory.get_rerank()

    def get_query_engine(self):
        """
        æ„å»ºå¸¦æœ‰ [è‡ªåŠ¨åˆå¹¶] + [æ··åˆæ£€ç´¢] + [é‡æ’åº] åŠŸèƒ½çš„æŸ¥è¯¢å¼•æ“
        """
        # 1. é‡æ–°åŠ è½½ Index
        storage_context = self.store_manager.get_storage_context()

        index = VectorStoreIndex.from_vector_store(
            vector_store=storage_context.vector_store,
            storage_context=storage_context,
            embed_model=self.embed_model
        )

        # 2. åŸºç¡€æ£€ç´¢å™¨ (Leaf Node Level)
        # ğŸ‘‡ã€å…³é”®ä¿®æ”¹ã€‘é…ç½®æ··åˆæ£€ç´¢ + æ‰©å¤§å¬å›
        base_retriever = index.as_retriever(
            similarity_top_k=settings.retrieval_top_k, # åˆç­› Top-50
            vector_store_query_mode="hybrid",          # å¼€å¯æ··åˆæ£€ç´¢æ¨¡å¼ (å‘é‡+å…³é”®è¯)
            alpha=0.5                                  # è¯­ä¹‰ä¸å…³é”®è¯æƒé‡å¹³è¡¡ (0.5=å„å ä¸€åŠ)
        )

        # 3. è‡ªåŠ¨åˆå¹¶æ£€ç´¢å™¨ (Auto-Merging)
        # å¦‚æœå­å—å‘½ä¸­è¶³å¤Ÿå¤šï¼Œè‡ªåŠ¨æ›¿æ¢ä¸ºçˆ¶å—
        retriever = AutoMergingRetriever(
            vector_retriever=base_retriever,
            storage_context=storage_context,
            verbose=True
        )

        # 4. æ„å»ºå¼•æ“ (Retriever + LLM)
        # ğŸ‘‡ã€å…³é”®ä¿®æ”¹ã€‘åŠ å…¥ Reranker ä½œä¸ºåç½®å¤„ç†å™¨
        query_engine = RetrieverQueryEngine.from_args(
            retriever=retriever,
            llm=self.llm,
            node_postprocessors=[self.reranker]        # é‡æ’åºï¼šä» 50 ä¸ªç²¾é€‰ä¸º 10 ä¸ª
        )

        return query_engine

    def as_langchain_tool(self):
        """
        è½¬æ¢ä¸º LangChain Toolï¼Œä¾› LangGraph ä½¿ç”¨
        """
        query_engine = self.get_query_engine()

        tool = QueryEngineTool(
            query_engine=query_engine,
            metadata=ToolMetadata(
                name="knowledge_base_search",
                description="ç”¨äºæ£€ç´¢å†…éƒ¨æ–‡æ¡£çŸ¥è¯†åº“ã€‚è¾“å…¥å®Œæ•´çš„é—®é¢˜è¿›è¡ŒæŸ¥è¯¢ã€‚",
            ),
        )

        return tool.to_langchain_tool()