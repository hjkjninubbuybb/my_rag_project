"""
[Architecture Role: Ingestion Pipeline (åŠ å·¥æµæ°´çº¿)]
æ­¤æ¨¡å—å®ç°äº† "ä¸‰æƒåˆ†ç«‹" æ¶æ„ä¸­çš„ ã€æ•°æ®åŠ å·¥å±‚ã€‘ã€‚

æ ¸å¿ƒèŒè´£:
1. [ETL Process] è¯»å–ç‰©ç†æ–‡ä»¶ -> æ–‡æœ¬åˆ‡ç‰‡ (Chunking) -> å‘é‡åŒ– (Embedding) -> å­˜å…¥ Qdrantã€‚
2. [Isolation] å®ƒåªè´Ÿè´£ "å…¥åº“" è¿™ä¸€åŠ¨ä½œï¼Œä¸è´Ÿè´£æ–‡ä»¶ç®¡ç†ã€‚
3. [Debugging] å†…ç½®äº†è¯¦ç»†çš„æ€§èƒ½ç›‘æ§æ—¥å¿—ï¼Œç”¨äºæ’æŸ¥å¡é¡¿é—®é¢˜ã€‚
"""

import time
import logging
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex
from app.core.engine.factory import ModelFactory
from app.core.engine.store import VectorStoreManager
from app.utils.logger import logger

# è·å–å…¨å±€ logger ä»¥ä¾¿è¾“å‡º DEBUG ä¿¡æ¯
sys_logger = logging.getLogger(__name__)

class IngestionService:
    def __init__(self):
        """
        åˆå§‹åŒ–åŠ å·¥è½¦é—´
        """
        self.store_manager = VectorStoreManager()
        self.embed_model = ModelFactory.get_embedding()
        self.node_parser = ModelFactory.get_text_splitter()

    async def process_directory(self, input_dir: str):
        """
        [Heavy Lifting] æ‰§è¡Œæ ¸å¿ƒå…¥åº“ä»»åŠ¡
        åŒ…å«è¯¦ç»†çš„æ€§èƒ½åŸ‹ç‚¹ (Profiling)
        """
        logger.info(f"ğŸ”¥ [DEBUG MODE] å¼€å§‹å¤„ç†ç›®å½•: {input_dir}")
        t0 = time.time()

        # 1. è¯»å–æ–‡ä»¶ (IO Bound)
        logger.info("ğŸ“‚ [Step 1] æ­£åœ¨è°ƒç”¨ SimpleDirectoryReader è¯»å–æ–‡ä»¶...")

        try:
            # æ˜¾å¼æŒ‡å®šåŠ è½½å™¨å‚æ•°ï¼Œé˜²æ­¢è‡ªåŠ¨æ¢æµ‹å¯¼è‡´çš„æ­»é”
            reader = SimpleDirectoryReader(
                input_dir=input_dir,
                recursive=True,
                # æ˜ç¡®æŒ‡å®šæ”¯æŒçš„åç¼€ï¼Œé˜²æ­¢å»è¯» .DS_Store æˆ–å…¶ä»–åƒåœ¾æ–‡ä»¶
                required_exts=[".pdf", ".md", ".txt", ".docx"],
                encoding="utf-8"
            )
            documents = reader.load_data()
        except Exception as e:
            logger.error(f"âŒ [Step 1 Error] è¯»å–æ–‡ä»¶å´©æºƒ: {e}")
            import traceback
            traceback.print_exc()
            raise e

        if not documents:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°æ–‡æ¡£ï¼Œè·³è¿‡å¤„ç†")
            return

        # ğŸ” [æ·±åº¦è¯Šæ–­] æ‰“å°è¯»å–åˆ°çš„å†…å®¹æ‘˜è¦
        t_io = time.time() - t0
        logger.info(f"âœ… è¯»å–å®Œæˆï¼ŒIOè€—æ—¶ {t_io:.2f}sã€‚å…±åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£å¯¹è±¡ã€‚")

        # æ‰“å°å‰ 3 ä¸ªæ–‡æ¡£çš„å¤´éƒ¨å†…å®¹ï¼Œæ£€æŸ¥æ˜¯å¦ä¹±ç 
        for i, doc in enumerate(documents[:3]):
            # æ›¿æ¢æ¢è¡Œç¬¦ä»¥å…æ—¥å¿—é”™ä¹±
            content_preview = doc.text[:100].replace('\n', '\\n')
            sys_logger.debug(f"ğŸ“„ [Doc Preview #{i}] Filename: {doc.metadata.get('file_name')} | Len: {len(doc.text)} | Content: {content_preview}...")

        # 2. ç”ŸæˆèŠ‚ç‚¹ (CPU Bound)
        logger.info(f"ğŸ”ª [Step 2] è¿›å…¥åˆ‡åˆ†å™¨: {self.node_parser.__class__.__name__}")
        t1 = time.time()

        try:
            # è¿™é‡Œå¯èƒ½ä¼šå› ä¸ºæ­£åˆ™å›æº¯å¯¼è‡´ CPU 100% å¡æ­»
            nodes = self.node_parser.get_nodes_from_documents(documents)
        except Exception as e:
            logger.error("âŒ [Step 2 Error] åˆ‡åˆ†é˜¶æ®µå´©æºƒï¼å¯èƒ½æ˜¯æ­£åˆ™æ­»å¾ªç¯æˆ–ç‰¹æ®Šå­—ç¬¦ã€‚")
            import traceback
            traceback.print_exc()
            raise e

        t_cpu = time.time() - t1
        logger.info(f"âœ… åˆ‡åˆ†å®Œæˆï¼ŒCPUè€—æ—¶ {t_cpu:.2f}sã€‚ç”Ÿæˆ {len(nodes)} ä¸ªåˆ‡ç‰‡ã€‚")

        # 3. è·å–å­˜å‚¨ä¸Šä¸‹æ–‡
        storage_context = self.store_manager.get_storage_context()

        # 4. å­˜å…¥ DocStore
        storage_context.docstore.add_documents(nodes)

        # 5. æ„å»ºç´¢å¼• (Network Bound - Embedding API)
        logger.info("ğŸš€ [Step 3] å¼€å§‹ Embedding å¹¶å†™å…¥ Qdrant...")
        t2 = time.time()

        VectorStoreIndex(
            nodes,
            storage_context=storage_context,
            embed_model=self.embed_model
        )

        t_net = time.time() - t2
        logger.success(f"ğŸ‰ å…¨éƒ¨å®Œæˆï¼Embeddingè€—æ—¶ {t_net:.2f}sã€‚")