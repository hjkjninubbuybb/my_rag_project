# 政策文档清洗 经验记录

**阶段**: 数据清洗（Ingestion 服务）

**问题**: PDF 解析后的 Markdown 段落被拆分成多行（PDF 硬换行导致），存在大量单换行符（69个）和双换行符（79个），段落破碎。影响：Recursive Text Splitter 无法正确识别语义边界，会在段落中间切分，导致检索质量下降。

**尝试**:
- 方案 1: 仅删除页码和页眉页脚 → 段落依然破碎，换行符过多（Single: 69, Double: 79），压缩率仅 3%
- 方案 2: 合并段落（在空行处结束段落）→ 仍产生 79 个双换行，因为原文每行后都有空行，无法有效合并
- 方案 3: 删除所有空行 → 0 个双换行，但段落、标题、列表全部粘在一起，Recursive Splitter 无法找到 \n\n 分隔符

**方案**: 智能空行插入策略 — 根据文档结构（标题/段落/列表）决定是否添加空行。核心规则：
1. **跳过所有原始空行**（消除 PDF 换行噪音）
2. **标题后添加空行**（`#` 开头的行后插入 `\n\n`，帮助 Recursive Splitter 识别章节边界）
3. **独立段落之间添加空行**（以句子结束符 `。！？；` 判断段落结束）
4. **列表项保持紧凑**（连续的列表项之间不插入空行，避免被切散到不同 chunk）
5. **列表项识别规则**：`^\d+[\.、)]` 或 `^（[一二三四五六七八九十]+）`

**标准**:
| 指标 | 改进前 | 改进后 | 目标 | 说明 |
|------|--------|--------|------|------|
| Compression Rate | 3% | 8.7% | >8% | (原始字符数 - 清洗后字符数) / 原始字符数 |
| Single Newlines | 69 | 16 | <30 | 段内换行数（应尽量少） |
| Double Newlines | 79 | 11 | 适度 | 段间分隔符数（Recursive Splitter 依赖此识别边界） |
| Chunking Quality | 段落破碎 | 语义完整 | 可视化验证 | 通过 `test_chunking_preview.py` 验证 chunks 语义完整性 |

**适用**: 政策与指标类文件（policy 类别），文档特征：
- **行长特征**：平均行长 30-50 字符（PDF 硬换行导致段落被拆分成多行）
- **列表特征**：大量有序列表（数字序号 `1.`、中文序号 `（一）`）
- **结构特征**：需要保留章节结构（标题层级 `#`、`##`）
- **切分策略**：使用 Recursive Text Splitter（分隔符优先级：`\n\n` > `\n` > `。` > `；`）

**为什么适用**：此策略的空行插入规则与 Recursive Splitter 的分隔符优先级完美匹配，确保优先在章节边界（`\n\n`）切分，其次在段落边界（`\n`），最后才在句子边界（`。`）切分。

**代码**:
- 文件位置: `services/ingestion/app/parsing/cleaner.py`
- 关键类: `PolicyCleaner`
- 关键方法: `_merge_paragraphs()` (智能空行插入), `_is_list_item()` (列表项识别), `_ends_with_sentence()` (句子结束判断)
- 验证工具: `services/ingestion/test_chunking_preview.py` (模拟 Recursive Splitter 切分效果)
